name: Run Scraper

on:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 16 * * *'  # Run daily at 16:00 UTC

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    - name: Install Chrome
      run: |
        wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get -y install google-chrome-stable
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Fix supabase initialization for GitHub Actions
      run: |
        # Create a patched version of the scraper.py file
        sed -i 's/supabase = create_client(SUPABASE_URL, SUPABASE_KEY)/try:\n    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\nexcept TypeError:\n    supabase = create_client(SUPABASE_URL, SUPABASE_KEY, options={})/g' scraper.py
    - name: Run scraper
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        BUCKET_NAME: screenshots
        TABLE_NAME: listings
        BASE_URL: https://www.adsafrica.co.za/category/65
        MAX_PAGES: 150
        MAX_WORKERS: 5
        # Disable any proxy settings
        HTTP_PROXY: ""
        HTTPS_PROXY: ""
        NO_PROXY: "*"
      run: |
        python scraper.py
